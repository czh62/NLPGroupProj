import json
import re

import requests

import config  # å‡è®¾ config.py å­˜åœ¨ï¼ŒåŒ…å« BASE_DATA_DIR, SF_API_KEY ç­‰é…ç½®
from BGEReranker import BGEReranker  # BGE é‡æ’åºå™¨æ¨¡å—
from BM25Retriever import BM25Retriever  # BM25 æ£€ç´¢å™¨æ¨¡å—
from HQSmallDataLoader import HQSmallDataLoader  # HotpotQA å°å‹æ•°æ®é›†åŠ è½½å™¨
from denseInstructionRetriever import Qwen3Retriever  # Qwen3 å¯†é›†æ£€ç´¢å™¨
from denseRetriever import BGERetriever  # BGE å¯†é›†æ£€ç´¢å™¨
from hybridRetrieveRerank import hybrid_retrieve_and_rerank  # æ··åˆæ£€ç´¢å’Œé‡æ’åºå‡½æ•°
from prompts import DECOMPOSITION_PROMPT, REWRITE_SUBQUERIES_PROMPT, RELEVANCE_AND_REWRITE_PROMPT, \
    GENERATE_ANSWER_PROMPT, SELF_CHECK_PROMPT, SYNTHESIZE_ANSWERS_PROMPT  # å¯¼å…¥æ–°çš„æç¤ºæ¨¡æ¿


# å‡½æ•°ï¼šæ¸…ç†å’Œè§£æ JSON å“åº”
def clean_and_parse_json_response(response_text, step_name=""):
    """
    æ¸…ç†å“åº”æ–‡æœ¬ä¸­çš„ JSON æ ‡è®°å¹¶è§£æä¸ºå­—å…¸ã€‚
    å‚æ•°:
    response_text (str): åŒ…å« JSON çš„å“åº”æ–‡æœ¬
    step_name (str): æ­¥éª¤åç§°ï¼Œç”¨äºæ—¥å¿—è®°å½•
    è¿”å›:
    dict: è§£æåçš„ JSON å­—å…¸
    """
    # print(f"ğŸ§¹ Cleaning JSON response for {step_name}...")
    # print(f"ğŸ“¥ Raw response: {response_text}")

    # å°è¯•ç›´æ¥è§£æ
    try:
        result = json.loads(response_text)
        # print(f"   âœ… Direct JSON parsing successful")
        return result
    except json.JSONDecodeError:
        # print(f"   âš ï¸ Direct parsing failed, attempting to extract JSON from markdown code blocks")
        pass

    # æ¸…ç†å¸¸è§çš„ JSON æ ‡è®°
    cleaned_text = response_text.strip()

    # ç§»é™¤ ```json å’Œ ``` æ ‡è®°
    cleaned_text = re.sub(r'^```json\s*', '', cleaned_text, flags=re.IGNORECASE)
    cleaned_text = re.sub(r'```\s*$', '', cleaned_text)

    # ç§»é™¤å…¶ä»–å¯èƒ½çš„ä»£ç å—æ ‡è®°
    cleaned_text = re.sub(r'^```\s*', '', cleaned_text)
    cleaned_text = re.sub(r'```\s*$', '', cleaned_text)

    # ç§»é™¤å¼€å¤´çš„ "json" å­—æ ·
    cleaned_text = re.sub(r'^json\s*', '', cleaned_text, flags=re.IGNORECASE)

    cleaned_text = cleaned_text.strip()
    # print(f"   ğŸ”§ Cleaned text: {cleaned_text}")

    # å°è¯•è§£ææ¸…ç†åçš„æ–‡æœ¬
    try:
        result = json.loads(cleaned_text)
        # print(f"   âœ… Cleaned JSON parsing successful")
        return result
    except json.JSONDecodeError as e:
        print(f"   âŒ Failed to parse JSON after cleaning: {e}")
        # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå°è¯•æ›´å®½æ¾çš„æå–æ–¹æ³•
        try:
            # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
            start_idx = cleaned_text.find('{')
            end_idx = cleaned_text.rfind('}') + 1
            if start_idx != -1 and end_idx != 0:
                json_str = cleaned_text[start_idx:end_idx]
                result = json.loads(json_str)
                print(f"   âœ… Extracted JSON parsing successful")
                return result
        except Exception as e2:
            print(f"   âŒ All JSON parsing attempts failed: {e2}")

    # å¦‚æœæ‰€æœ‰è§£æéƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æ„
    default_result = {
        "is_relevant": False,
        "reason": "JSON parsing failed",
        "improved_query": ""
    }
    print(f"   âš ï¸ Returning default result due to parsing failure")
    return default_result


# å‡½æ•°ï¼šè°ƒç”¨ SiliconFlow API æ¥ç”Ÿæˆ LLM å“åº”
def call_llm(prompt, max_tokens=512, temperature=0.7, step_name="", expect_json=False):
    """
    è°ƒç”¨ SiliconFlow API æ¥å¤„ç†ç»™å®šçš„æç¤ºã€‚
    å‚æ•°:
    prompt (str): è¾“å…¥çš„æç¤ºæ–‡æœ¬ã€‚
    max_tokens (int): æœ€å¤§ç”Ÿæˆçš„ token æ•°é‡ï¼Œé»˜è®¤ 512ã€‚
    temperature (float): ç”Ÿæˆçš„æ¸©åº¦å‚æ•°ï¼Œé»˜è®¤ 0.7ã€‚
    step_name (str): å½“å‰æ­¥éª¤åç§°ï¼Œç”¨äºæ—¥å¿—è®°å½•ã€‚
    expect_json (bool): æ˜¯å¦æœŸæœ›è¿”å› JSON æ ¼å¼ï¼Œé»˜è®¤ Falseã€‚
    è¿”å›:
    str: API è¿”å›çš„å“åº”å†…å®¹ã€‚
    å¼‚å¸¸:
    å¦‚æœ API è°ƒç”¨å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸ã€‚
    """
    # print(f"{'-' * 80}")
    # print(f"ğŸ¤– LLM CALL - {step_name}")
    # print(f"ğŸ“¤ PROMPT SENT:\n{prompt}")
    # print(f"{'-' * 80}")

    headers = {
        "Authorization": f"Bearer {config.SF_API_KEY}",
        "Content-Type": "application/json"
    }
    data = {
        "model": config.SF_LLM_MODEL_NAME,
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "max_tokens": max_tokens,
        "temperature": temperature
    }
    response = requests.post(config.SF_API_LLM_URL, headers=headers, json=data)
    if response.status_code == 200:
        result = response.json()["choices"][0]["message"]["content"].strip()
        # print(f"ğŸ“¥ RESPONSE RECEIVED:\n{result}")
        # print(f"{'=' * 80}")

        # å¦‚æœæœŸæœ› JSON æ ¼å¼ï¼Œè¿›è¡Œæ¸…ç†å’Œè§£æ
        if expect_json:
            return clean_and_parse_json_response(result, step_name)
        else:
            return result
    else:
        error_msg = f"API call failed: {response.text}"
        print(f"âŒ ERROR: {error_msg}")
        print(f"{'=' * 80}")
        raise Exception(error_msg)


# å‡½æ•°ï¼šåˆå§‹åŒ–æ£€ç´¢å™¨
def initialize_retrievers():
    """
    åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨å’Œå„ç§æ£€ç´¢å™¨ã€‚
    è¿”å›:
    tuple: åŒ…å« BM25 æ£€ç´¢å™¨ã€BGE æ£€ç´¢å™¨ã€Qwen3 æ£€ç´¢å™¨ã€BGE é‡æ’åºå™¨ å’Œ æ–‡æ¡£ ID åˆ°æ–‡æœ¬çš„æ˜ å°„ã€‚
    """
    print("ğŸ”„ Initializing retrievers...")
    data_loader = HQSmallDataLoader(config.BASE_DATA_DIR)
    all_doc_ids, all_documents = data_loader.load_collection(config.COLLECTION_PATH)
    doc_id_to_text = dict(zip(all_doc_ids, all_documents))

    if config.SF_API_KEY:
        bge_reranker = BGEReranker(api_key=config.SF_API_KEY)
        bm25_retriever = BM25Retriever()
        qwen3_retriever = Qwen3Retriever(api_key=config.SF_API_KEY)
        bge_retriever = BGERetriever(api_key=config.SF_API_KEY)
    else:
        bge_reranker = BGEReranker()
        bm25_retriever = BM25Retriever()
        qwen3_retriever = Qwen3Retriever()
        bge_retriever = BGERetriever()

    bm25_retriever.load_index(config.BM25_INDEX_PATH)
    bge_retriever.load_index(config.BGE_INDEX_DIR)
    qwen3_retriever.load_index(config.QWEN_INDEX_DIR)
    print("âœ… Retrievers initialized successfully")
    return bm25_retriever, bge_retriever, qwen3_retriever, bge_reranker, doc_id_to_text


# å‡½æ•°ï¼šæ£€ç´¢å’Œæ ¼å¼åŒ–æ–‡æ¡£ï¼ˆåªå–50åˆ†ä»¥ä¸Šçš„ç»“æœï¼‰
def retrieve_documents(query, bm25_retriever, bge_retriever, bge_reranker, doc_id_to_text, retrieval_top_k=50,
                       rerank_top_k=10, min_score=50):
    """
    ä½¿ç”¨æ··åˆæ£€ç´¢å’Œé‡æ’åºæ¥æ£€ç´¢æ–‡æ¡£ï¼Œåªè¿”å›åˆ†æ•°é«˜äºé˜ˆå€¼çš„æ–‡æ¡£ã€‚
    å‚æ•°:
    query (str): æŸ¥è¯¢å­—ç¬¦ä¸²ã€‚
    bm25_retriever: BM25 æ£€ç´¢å™¨å®ä¾‹ã€‚
    bge_retriever: BGE æ£€ç´¢å™¨å®ä¾‹ã€‚
    bge_reranker: BGE é‡æ’åºå™¨å®ä¾‹ã€‚
    doc_id_to_text (dict): æ–‡æ¡£ ID åˆ°æ–‡æœ¬çš„æ˜ å°„ã€‚
    retrieval_top_k (int): åˆå§‹æ£€ç´¢çš„ top k å€¼ï¼Œé»˜è®¤ 50ã€‚
    rerank_top_k (int): é‡æ’åºåçš„ top k å€¼ï¼Œé»˜è®¤ 10ã€‚
    min_score (int): æœ€å°åˆ†æ•°é˜ˆå€¼ï¼Œé»˜è®¤ 50ã€‚
    è¿”å›:
    tuple: åŒ…å«æ£€ç´¢åˆ°çš„æ–‡æ¡£æ–‡æœ¬åˆ—è¡¨å’Œæ–‡æ¡£ ID åˆ—è¡¨ã€‚
    """
    print(f"ğŸ” RETRIEVING DOCUMENTS FOR QUERY: '{query}'")
    print(f"Retrieval top_k: {retrieval_top_k}, Rerank top_k: {rerank_top_k}, Min score: {min_score}")

    results = hybrid_retrieve_and_rerank(
        query=query,
        first_retriever=bm25_retriever,
        second_retriever=bge_retriever,
        reranker=bge_reranker,
        doc_id_to_text_map=doc_id_to_text,
        retrieval_top_k=retrieval_top_k,
        rerank_top_k=rerank_top_k
    )

    # è¿‡æ»¤åˆ†æ•°é«˜äºé˜ˆå€¼çš„æ–‡æ¡£
    filtered_results = [(doc_id, score) for doc_id, score in results if score >= min_score]

    if not filtered_results:
        print(f"âš ï¸ No documents found with score >= {min_score}, using top document regardless of score")
        filtered_results = [results[0]] if results else []

    doc_texts = [doc_id_to_text[doc_id] for doc_id, _ in filtered_results]
    doc_ids = [doc_id for doc_id, _ in filtered_results]

    print(f"âœ… Retrieved {len(doc_texts)} documents (score >= {min_score})")
    for i, (doc_id, (_, score)) in enumerate(zip(doc_ids, filtered_results)):
        print(f"   Document {i + 1} (ID: {doc_id}, Score: {score:.2f}): {doc_texts[i][:100]}...")

    return doc_texts, doc_ids


# å‡½æ•°ï¼šé‡å†™å­æŸ¥è¯¢ï¼ˆåŸºäºä¾èµ–å…³ç³»å’Œå‰åºç­”æ¡ˆï¼‰
def rewrite_subqueries(original_query, sub_queries, previous_answers):
    """
    æ ¹æ®ä¾èµ–å…³ç³»å’Œå‰åºç­”æ¡ˆé‡å†™å­æŸ¥è¯¢ã€‚
    å‚æ•°:
    original_query (str): åŸå§‹å¤æ‚é—®é¢˜
    sub_queries (list): å­é—®é¢˜åˆ—è¡¨
    previous_answers (dict): å‰åºé—®é¢˜çš„ç­”æ¡ˆ
    è¿”å›:
    list: é‡å†™åçš„æŸ¥è¯¢åˆ—è¡¨
    """
    print(f"ğŸ”„ REWRITING SUBQUERIES WITH DEPENDENCIES")
    print(f"Original query: {original_query}")
    print(f"Sub queries: {json.dumps(sub_queries, indent=2, ensure_ascii=False)}")
    print(f"Previous answers: {previous_answers}")

    rewrite_prompt = REWRITE_SUBQUERIES_PROMPT.format(
        original_query=original_query,
        sub_queries_json=json.dumps(sub_queries, ensure_ascii=False),
        previous_answers_json=json.dumps(previous_answers, ensure_ascii=False)
    )

    rewrite_response = call_llm(rewrite_prompt, step_name="REWRITE SUBQUERIES", expect_json=True)

    if isinstance(rewrite_response, dict) and "rewritten_queries" in rewrite_response:
        rewritten_queries = rewrite_response["rewritten_queries"]
        print(f"âœ… Subqueries rewritten successfully")
        for rq in rewritten_queries:
            print(
                f"   {rq['original_id']}: '{rq['original_query']}' -> '{rq['rewritten_query']}'")
        return rewritten_queries
    else:
        print(f"âŒ Failed to rewrite subqueries, using original queries")
        # è¿”å›é»˜è®¤çš„é‡å†™ç»“æœ
        return [
            {
                "original_id": sq["id"],
                "original_query": sq["query"],
                "rewritten_query": sq["query"],
            }
            for sq in sub_queries
        ]


# å‡½æ•°ï¼šå¤„ç†å•ä¸ªæŸ¥è¯¢ï¼ˆæ”¯æŒä¸Šä¸‹æ–‡ä¾èµ–ï¼‰
def process_single_query(query, bm25_retriever, bge_retriever, bge_reranker, doc_id_to_text, previous_answers=None):
    """
    å¤„ç†å•ä¸ªæŸ¥è¯¢ï¼ŒåŒ…æ‹¬æ£€ç´¢ã€ç›¸å…³æ€§åˆ¤æ–­ã€é‡å†™å’Œç­”æ¡ˆç”Ÿæˆã€‚
    å‚æ•°:
    query (str): æŸ¥è¯¢å­—ç¬¦ä¸²ã€‚
    bm25_retriever: BM25 æ£€ç´¢å™¨å®ä¾‹ã€‚
    bge_retriever: BGE æ£€ç´¢å™¨å®ä¾‹ã€‚
    bge_reranker: BGE é‡æ’åºå™¨å®ä¾‹ã€‚
    doc_id_to_text (dict): æ–‡æ¡£ ID åˆ°æ–‡æœ¬çš„æ˜ å°„ã€‚
    previous_answers (dict): å‰åºé—®é¢˜çš„ç­”æ¡ˆï¼Œç”¨äºä¸Šä¸‹æ–‡ä¾èµ–ã€‚
    è¿”å›:
    tuple: åŒ…å«ç”Ÿæˆçš„ç­”æ¡ˆå’Œæœ€ç»ˆä½¿ç”¨çš„æŸ¥è¯¢ã€‚
    """
    original_query = query  # ä¿å­˜åŸå§‹æŸ¥è¯¢
    current_query = query
    final_query = query  # ä¿å­˜æœ€ç»ˆä½¿ç”¨çš„æŸ¥è¯¢
    max_retries = 3

    # æ„å»ºä¸Šä¸‹æ–‡ä¾èµ–ä¿¡æ¯
    context_dependency = ""
    if previous_answers:
        context_dependency = "å‰åºé—®é¢˜ç­”æ¡ˆï¼š\n"
        for qid, ans in previous_answers.items():
            context_dependency += f"- {qid}: {ans}\n"

    for attempt in range(max_retries):
        print(f"{'-' * 60}")
        print(f"ğŸ” ATTEMPT {attempt + 1}/{max_retries}")
        print(f"   Current query: '{current_query}'")
        if previous_answers:
            print(f"   Context from previous answers: {previous_answers}")

        # æ£€ç´¢æ–‡æ¡£ï¼ˆåªå–50åˆ†ä»¥ä¸Šçš„ç»“æœï¼‰
        doc_texts, doc_ids = retrieve_documents(current_query, bm25_retriever, bge_retriever, bge_reranker,
                                                doc_id_to_text)
        documents_str = "\n".join([f"Doc {i + 1}: {text}" for i, text in enumerate(doc_texts)])

        # æ­¥éª¤ 2: ç›¸å…³æ€§åˆ¤æ–­ + æŸ¥è¯¢é‡å†™ï¼ˆæ”¯æŒä¸Šä¸‹æ–‡ä¾èµ–ï¼‰
        print(f"ğŸ“ STEP 2: RELEVANCE AND REWRITE")
        rel_rewrite_prompt = RELEVANCE_AND_REWRITE_PROMPT.format(
            query=current_query,
            context_dependency=context_dependency,
            documents=documents_str
        )
        rel_rewrite_response = call_llm(
            rel_rewrite_prompt,
            step_name=f"RELEVANCE AND REWRITE (Attempt {attempt + 1})",
            expect_json=True
        )

        # å¤„ç†å“åº”
        if isinstance(rel_rewrite_response, dict):
            is_relevant = rel_rewrite_response.get("is_relevant", False)
            reason = rel_rewrite_response.get("reason", "")
            improved_query = rel_rewrite_response.get("improved_query", "")
            needs_context = rel_rewrite_response.get("needs_context", False)
            print(
                f"   âœ… Relevance and rewrite result: is_relevant={is_relevant}, reason={reason}, needs_context={needs_context}")
            if improved_query:
                print(f"   ğŸ’¡ Improved query: {improved_query}")
        else:
            print(f"   âŒ Unexpected response type for relevance and rewrite: {type(rel_rewrite_response)}")
            is_relevant = False
            reason = "Unexpected response type"
            improved_query = ""
            needs_context = False

        # å¦‚æœéœ€è¦ä¸Šä¸‹æ–‡ä½†å½“å‰æŸ¥è¯¢æ²¡æœ‰åŒ…å«ï¼Œåˆ™æ•´åˆå‰åºç­”æ¡ˆ
        if needs_context and previous_answers and not any(
                str(qid).lower() in current_query.lower() for qid in previous_answers.keys()):
            context_info = " ".join([f"{ans}" for ans in previous_answers.values()])
            current_query = f"{current_query} {context_info}"
            print(f"   ğŸ”„ Enhanced query with context: '{current_query}'")
            continue  # é‡æ–°å°è¯•å½“å‰æŸ¥è¯¢

        if is_relevant:
            print(f"   âœ… Documents are relevant, proceeding to answer generation")
            final_query = current_query  # ä½¿ç”¨å½“å‰æŸ¥è¯¢ä½œä¸ºæœ€ç»ˆæŸ¥è¯¢
            break
        else:
            print(f"   âš ï¸ Documents not relevant, using improved query for next attempt")
            if improved_query and improved_query.strip():
                current_query = improved_query.strip()
                print(f"   ğŸ”„ Using improved query: '{current_query}'")
            else:
                print(f"   âš ï¸ No improved query provided, using original query")
                current_query = query

    # å¦‚æœä¸‰æ¬¡å°è¯•åä»ç„¶ä¸ç›¸å…³ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢ç›´æ¥æ£€ç´¢å¹¶ç”Ÿæˆç­”æ¡ˆ
    if not is_relevant:
        print(f"   âŒ Failed to find relevant documents after {max_retries} attempts")
        print(f"   ğŸ”„ FALLBACK: Using original query '{original_query}' for direct retrieval and answer generation")

        # ä½¿ç”¨åŸå§‹æŸ¥è¯¢ç›´æ¥æ£€ç´¢æ–‡æ¡£
        doc_texts, doc_ids = retrieve_documents(original_query, bm25_retriever, bge_retriever, bge_reranker,
                                                doc_id_to_text)
        documents_str = "\n".join([f"Doc {i + 1}: {text}" for i, text in enumerate(doc_texts)])

        # æ„å»ºå‰åºç­”æ¡ˆä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        previous_answers_str = ""
        if previous_answers:
            previous_answers_str = "ç›¸å…³èƒŒæ™¯ä¿¡æ¯ï¼š\n"
            for qid, ans in previous_answers.items():
                previous_answers_str += f"- {ans}\n"

        # ç›´æ¥ç”Ÿæˆç­”æ¡ˆï¼Œä¸è¿›è¡Œç›¸å…³æ€§æ£€æŸ¥
        context = "\n\n".join(doc_texts)
        gen_prompt = GENERATE_ANSWER_PROMPT.format(
            query=original_query,
            previous_answers=previous_answers_str,
            context=context
        )
        answer = call_llm(gen_prompt, step_name="FALLBACK ANSWER GENERATION")
        print(f"âœ… Fallback answer generated: {answer}")

        # è·³è¿‡è‡ªæ£€æ­¥éª¤ï¼Œç›´æ¥è¿”å›ç­”æ¡ˆ
        return answer, original_query

    # æ­¥éª¤ 3: ç”Ÿæˆç­”æ¡ˆ - æ”¯æŒä¸Šä¸‹æ–‡ä¼ é€’
    print(f"ğŸ“ STEP 3: GENERATE ANSWER")
    print(f"Using final query for answer generation: '{final_query}'")
    context = "\n\n".join(doc_texts)

    # æ„å»ºå‰åºç­”æ¡ˆä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
    previous_answers_str = ""
    if previous_answers:
        previous_answers_str = "ç›¸å…³èƒŒæ™¯ä¿¡æ¯ï¼š\n"
        for qid, ans in previous_answers.items():
            previous_answers_str += f"- {ans}\n"

    gen_prompt = GENERATE_ANSWER_PROMPT.format(
        query=final_query,
        previous_answers=previous_answers_str,
        context=context
    )
    answer = call_llm(gen_prompt, step_name="GENERATE ANSWER")
    print(f"âœ… Answer generated: {answer}")

    # æ­¥éª¤ 4: ç­”æ¡ˆè‡ªæ£€ - ä½¿ç”¨æœ€ç»ˆæŸ¥è¯¢
    print(f"ğŸ“ STEP 4: SELF-CHECK")
    self_check_prompt = SELF_CHECK_PROMPT.format(
        query=final_query,  # ä½¿ç”¨æœ€ç»ˆæŸ¥è¯¢
        answer=answer,
        documents=documents_str
    )
    self_check_response = call_llm(self_check_prompt, step_name="SELF-CHECK", expect_json=True)

    # å¤„ç†è‡ªæ£€å“åº”
    if isinstance(self_check_response, dict):
        is_valid = self_check_response.get("is_valid", False)
        issues = self_check_response.get("issues", "")
        revised_answer = self_check_response.get("revised_answer", "")
        print(f"ğŸ” Self-check result: is_valid={is_valid}, issues={issues}")
        if revised_answer and revised_answer.strip():
            print(f"ğŸ“ Using revised answer: {revised_answer}")
            return revised_answer.strip(), final_query
    else:
        print(f"âŒ Unexpected response type for self-check: {type(self_check_response)}")

    return answer, final_query


# å‡½æ•°ï¼šæŒ‰ä¾èµ–å…³ç³»æ’åºå­é—®é¢˜
def sort_subqueries_by_dependency(sub_queries):
    """
    æ ¹æ®ä¾èµ–å…³ç³»å¯¹å­é—®é¢˜è¿›è¡Œæ‹“æ‰‘æ’åºã€‚
    å‚æ•°:
    sub_queries (list): å­é—®é¢˜åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« id, query, depends_on
    è¿”å›:
    list: æŒ‰ä¾èµ–å…³ç³»æ’åºåçš„å­é—®é¢˜åˆ—è¡¨
    """
    # æ„å»ºä¾èµ–å›¾
    graph = {}
    id_to_query = {}

    for sq in sub_queries:
        qid = sq.get('id', '')
        graph[qid] = sq.get('depends_on', [])
        id_to_query[qid] = sq

    # æ‹“æ‰‘æ’åº
    visited = set()
    temp_visited = set()
    result = []

    def visit(node):
        if node in temp_visited:
            raise ValueError(f"Circular dependency detected involving {node}")
        if node not in visited:
            temp_visited.add(node)
            for dep in graph.get(node, []):
                visit(dep)
            temp_visited.remove(node)
            visited.add(node)
            result.append(id_to_query[node])

    for node in graph:
        if node not in visited:
            visit(node)

    return result


# ç®¡é“å‡½æ•°ï¼šRAG ç®¡é“å®ç°ï¼ˆæ”¯æŒä¾èµ–å…³ç³»å’Œå­æŸ¥è¯¢é‡å†™ï¼‰
def rag_pipeline(query):
    """
    RAG (Retrieval-Augmented Generation) ç®¡é“çš„ä¸»å‡½æ•°ã€‚
    å¤„ç†æŸ¥è¯¢ï¼ŒåŒ…æ‹¬åˆ†è§£ã€æ£€ç´¢ã€ç›¸å…³æ€§åˆ¤æ–­ã€é‡å†™ã€ç”Ÿæˆç­”æ¡ˆã€è‡ªæ£€å’Œåˆæˆã€‚
    æ”¯æŒä¾èµ–å…³ç³»çš„å­é—®é¢˜å¤„ç†å’Œå­æŸ¥è¯¢é‡å†™ã€‚
    å‚æ•°:
    query (str): è¾“å…¥æŸ¥è¯¢ã€‚
    è¿”å›:
    str: æœ€ç»ˆç”Ÿæˆçš„ç­”æ¡ˆã€‚
    """
    print(f"ğŸ¯ STARTING RAG PIPELINE FOR QUERY: '{query}'")

    bm25_retriever, bge_retriever, qwen3_retriever, bge_reranker, doc_id_to_text = initialize_retrievers()

    # æ­¥éª¤ 1: æŸ¥è¯¢åˆ†è§£
    print("=" * 100)
    print(f"ğŸ“ STEP 1: QUERY DECOMPOSITION")
    print(f"Original query: '{query}'")

    decomp_prompt = DECOMPOSITION_PROMPT.format(query=query)
    decomp_response = call_llm(decomp_prompt, step_name="QUERY DECOMPOSITION", expect_json=True)

    # å¤„ç†åˆ†è§£å“åº”
    if isinstance(decomp_response, dict):
        needs_decomp = decomp_response.get("needs_decomposition", False)
        sub_queries_raw = decomp_response.get("sub_queries", [])
        print(f"âœ… Decomposition result: needs_decomposition={needs_decomp}")

        # å¤„ç†å­é—®é¢˜ç»“æ„
        processed_sub_queries = []
        if needs_decomp and sub_queries_raw:
            for i, sq in enumerate(sub_queries_raw):
                if isinstance(sq, dict):
                    # æ–°æ ¼å¼ï¼šåŒ…å« id, query, depends_on
                    processed_sub_queries.append(sq)
                else:
                    # æ—§æ ¼å¼ï¼šåªæœ‰ query å­—ç¬¦ä¸²
                    processed_sub_queries.append({
                        "query": sq,
                        "id": f"q{i + 1}",
                        "depends_on": []
                    })

            # æŒ‰ä¾èµ–å…³ç³»æ’åº
            try:
                sorted_sub_queries = sort_subqueries_by_dependency(processed_sub_queries)
                print(f"ğŸ“‹ Sorted sub-queries by dependency:")
                for i, sq in enumerate(sorted_sub_queries):
                    deps = sq.get('depends_on', [])
                    print(f"   {i + 1}. [{sq['id']}] {sq['query']} (depends on: {deps})")
            except ValueError as e:
                print(f"âš ï¸ Dependency sorting failed: {e}, using original order")
                sorted_sub_queries = processed_sub_queries
        else:
            sorted_sub_queries = []
    else:
        print(f"âŒ Unexpected response type for decomposition: {type(decomp_response)}")
        needs_decomp = False
        sorted_sub_queries = []

    # å†³å®šå¤„ç†å“ªäº›æŸ¥è¯¢
    if needs_decomp and sorted_sub_queries:
        queries_to_process = sorted_sub_queries
    else:
        queries_to_process = [{"query": query, "id": "q1", "depends_on": []}]

    print(f"ğŸ“‹ Queries to process: {len(queries_to_process)}")

    # æŒ‰é¡ºåºå¤„ç†å­é—®é¢˜ï¼Œæ”¯æŒä¾èµ–å…³ç³»å’Œå­æŸ¥è¯¢é‡å†™
    sub_answers = {}  # å­˜å‚¨æ‰€æœ‰å­é—®é¢˜çš„ç­”æ¡ˆï¼Œç”¨äºä¾èµ–ä¼ é€’
    sub_answers_with_dependencies = []  # ç”¨äºæœ€ç»ˆåˆæˆçš„ç»“æ„åŒ–ä¿¡æ¯

    for i, sub_query in enumerate(queries_to_process):
        print("=" * 100)
        print(f"ğŸ”„ PROCESSING SUB-QUERY {i + 1}/{len(queries_to_process)}")
        print(f"   Query ID: {sub_query['id']}")
        print(f"   Query: '{sub_query['query']}'")
        print(f"   Depends on: {sub_query.get('depends_on', [])}")

        # æ”¶é›†ä¾èµ–é—®é¢˜çš„ç­”æ¡ˆ
        previous_answers = {}
        for dep_id in sub_query.get('depends_on', []):
            if dep_id in sub_answers:
                previous_answers[dep_id] = sub_answers[dep_id]
            else:
                print(f"   âš ï¸ Warning: Dependency {dep_id} not found in answers")

        # æ­¥éª¤ 1.5: å­æŸ¥è¯¢é‡å†™ï¼ˆå¦‚æœéœ€è¦ï¼‰
        current_query_to_process = sub_query['query']

        if previous_answers and sub_query.get('depends_on', []):
            # æœ‰ä¾èµ–å…³ç³»ï¼Œéœ€è¦é‡å†™æŸ¥è¯¢
            rewritten_queries = rewrite_subqueries(query, [sub_query], previous_answers)
            if rewritten_queries:
                rewritten_query = rewritten_queries[0]  # åªæœ‰ä¸€ä¸ªæŸ¥è¯¢
                current_query_to_process = rewritten_query['rewritten_query']
                print(f"   ğŸ”„ Rewritten query: '{current_query_to_process}'")

        # å¤„ç†å½“å‰å­é—®é¢˜ï¼ˆå¦‚æœéœ€è¦æ£€ç´¢ï¼‰
        answer, final_used_query = process_single_query(
            current_query_to_process,
            bm25_retriever,
            bge_retriever,
            bge_reranker,
            doc_id_to_text,
            previous_answers=previous_answers
        )

        # å­˜å‚¨ç­”æ¡ˆ
        sub_answers[sub_query['id']] = {
            "question": final_used_query,  # æœ€ç»ˆä½¿ç”¨çš„æŸ¥è¯¢
            "answer": answer
        }

        # è®°å½•ç”¨äºåˆæˆçš„ä¿¡æ¯
        sub_answers_with_dependencies.append({
            "id": sub_query['id'],
            "query": final_used_query,
            "answer": answer,
            "depends_on": sub_query.get('depends_on', [])
        })

        print(f"âœ… Sub-answer {sub_query['id']} completed: {answer[:100]}...")

    # æ­¥éª¤ 5: å¤šå­ç­”æ¡ˆåˆæˆï¼ˆå¦‚æœéœ€è¦ï¼‰
    print("=" * 100)
    print(f"ğŸ¯ FINAL STEP: SYNTHESIZE ANSWERS")

    if needs_decomp and len(sub_answers_with_dependencies) > 1:
        print(f"ğŸ“¦ Synthesizing {len(sub_answers_with_dependencies)} sub-answers into final answer")

        # æ„å»ºç”¨äºåˆæˆçš„ç»“æ„åŒ–ä¿¡æ¯
        sub_answers_str = "\n\n".join([
            f"Sub-query {item['id']} (depends on {item['depends_on']}): {item['query']}\nAnswer: {item['answer']}"
            for item in sub_answers_with_dependencies
        ])

        synth_prompt = SYNTHESIZE_ANSWERS_PROMPT.format(
            original_query=query,
            sub_answers_with_dependencies=sub_answers_str
        )
        final_answer = call_llm(synth_prompt, step_name="SYNTHESIZE ANSWERS")
        print(f"âœ… Final synthesized answer ready")
    else:
        # å•ä¸ªç­”æ¡ˆçš„æƒ…å†µ
        if sub_answers_with_dependencies:
            final_answer = sub_answers_with_dependencies[0]['answer']
        else:
            final_answer = "æ ¹æ®æä¾›çš„èµ„æ–™æ— æ³•ç¡®å®š"
        print(f"âœ… Using single answer as final answer")

    return final_answer


# ç¤ºä¾‹ç”¨æ³•
if __name__ == "__main__":
    sample_query = "What direction does the river that Austrolebias bellotti are found in flow?"
    print("ğŸš€ STARTING RAG PIPELINE DEMO")
    print("=" * 100)
    answer = rag_pipeline(sample_query)
    print(f"ğŸ‰ FINAL RESULT")
    print("=" * 100)
    print(f"ğŸ“ Original Query: {sample_query}")
    print(f"ğŸ’¡ Final Answer: {answer}")
    print("=" * 100)